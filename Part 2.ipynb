{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "f9db377eb99f2f0001687ee5f0a8c7059c0f00fe46be8b7ead3eb64d7e1b83ff"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "source": [
    "For both tasks in Part 2, we will re-use the same *CompareResult* function used in the notebook for Part 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareResult(img1, img2, metric):\n",
    "    \"\"\"Compares two images using either SSD or MSE error\"\"\"\n",
    "\n",
    "    if metric==1: #Sum of Squared Distance Error (SSD)\n",
    "        error = np.sum((img1-img2)**2)\n",
    "    elif metric==2: #Mean Squared Error (MSE)\n",
    "        error = np.sum((img1.astype(\"float\") - img2.astype(\"float\")) ** 2)\n",
    "        error /= float(img1.shape[0] * img1.shape[1])\n",
    "    return error"
   ]
  },
  {
   "source": [
    "# Task A"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "6 different sets of images from the COTS dataset are used. These are the statues, glasses, books, footwear, mugs and gadgets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sets = {} # 'set name': (s1, s2, mask)\n",
    "image_sets['statue'] = (cv2.imread(\"Images/statues_oc/2_colour.jpeg\"), cv2.imread(\"Images/statues_oc/3_colour.jpeg\"), cv2.imread(\"Images/statues_oc/masks/statues_oc_3_colour_mask_5_mask.png\", 0))\n",
    "\n",
    "image_sets['glasses'] = (cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/shooters_oc/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/shooters_oc/3_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/shooters_oc/masks/shooters_oc_3_colour_mask_0_mask.png\", 0))\n",
    "\n",
    "image_sets['books'] = (cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/academic_book_oc/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/academic_book_oc/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/academic_book_oc/masks/ac_oc_3_colour_mask_5_mask.png\", 0))\n",
    "\n",
    "image_sets['footwear'] = (cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/footwear_no/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/footwear_no/3_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/footwear_no/masks/footware_no_3_colour_mask_2_mask.png\", 0))\n",
    "\n",
    "image_sets['mugs'] = (cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/mugs_no/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/mugs_no/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/mugs_no/masks/3_colour_mask_2_mask.png\", 0))\n",
    "\n",
    "image_sets['tech'] = (cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/tech_no/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/tech_no/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/tech_no/masks/tech_no_3_colour_mask_2_mask.png\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = cv2.imread(\"Images/statues_oc/2_colour.jpeg\")\n",
    "s2 = cv2.imread(\"Images/statues_oc/3_colour.jpeg\")\n",
    "mask = cv2.imread(\"Images/statues_oc/masks/statues_oc_3_colour_mask_5_mask.png\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "painted1 = cv2.inpaint(s2, mask, 20, cv2.INPAINT_NS)\n",
    "painted2 = cv2.inpaint(s2, mask, 20, cv2.INPAINT_TELEA)\n",
    "cv2.imshow(\"NS\", painted1)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"TELEA\", painted2)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "# Task B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "com1 = cv2.imread(\"COTSDataset/Part 3 - Complex Background/cupsA_nw_no/3_colour.jpeg\", 1)\n",
    "commask1 = cv2.imread(\"COTSDataset/Part 3 - Complex Background/masks/cupsa_nw_no/1_colour.png\", 0)\n",
    "cv2.imshow(\"Inpainted image\", com1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "inp1 = cv2.inpaint(com1, commask1, 150, cv2.INPAINT_TELEA)\n",
    "cv2.imshow(\"Inpainted image\", inp1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareResult(img1, img2, metric):\n",
    "    \"\"\"Compares the blended image with the scene with 2 objects\"\"\"\n",
    "\n",
    "    if metric==1: #Sum of Squared Distance Error (SSD)\n",
    "        error = np.sum((img1-img2)**2)\n",
    "    elif metric==2: #Mean Squared Error (MSE)\n",
    "        error = np.sum((img1.astype(\"float\") - img2.astype(\"float\")) ** 2)\n",
    "        error /= float(img1.shape[0] * img1.shape[1])\n",
    "    return error"
   ]
  }
 ]
}