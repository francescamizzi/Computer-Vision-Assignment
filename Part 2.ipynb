{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit"
  },
  "interpreter": {
   "hash": "f9db377eb99f2f0001687ee5f0a8c7059c0f00fe46be8b7ead3eb64d7e1b83ff"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "source": [
    "For both tasks in Part 2, we will re-use the same *CompareResult* function used in the notebook for Part 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareResult(img1, img2, metric):\n",
    "    \"\"\"Compares two images using either SSD or MSE error\"\"\"\n",
    "\n",
    "    if metric==1: #Sum of Squared Distance Error (SSD)\n",
    "        error = np.sum((img1-img2)**2)\n",
    "    elif metric==2: #Mean Squared Error (MSE)\n",
    "        error = np.sum((img1.astype(\"float\") - img2.astype(\"float\")) ** 2)\n",
    "        error /= float(img1.shape[0] * img1.shape[1])\n",
    "    return error"
   ]
  },
  {
   "source": [
    "# Task A"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "6 different sets of images from the COTS dataset are used. These are the statues, glasses, books, footwear, mugs and gadgets. The S1, S2 and masks (as used in the research paper) were loaded and stored in a dictionary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_sets = {} # 'set name': (s1, s2, mask)\n",
    "image_sets['statue'] = (cv2.imread(\"Images/statues_oc/2_colour.jpeg\"), cv2.imread(\"Images/statues_oc/3_colour.jpeg\"), cv2.imread(\"Images/statues_oc/masks/statues_oc_3_colour_mask_5_mask.png\", 0))\n",
    "\n",
    "image_sets['glasses'] = (cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/shooters_oc/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/shooters_oc/3_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/shooters_oc/masks/shooters_oc_3_colour_mask_0_mask.png\", 0))\n",
    "\n",
    "image_sets['books'] = (cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/academic_book_oc/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/academic_book_oc/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/academic_book_oc/masks/ac_oc_3_colour_mask_5_mask.png\", 0))\n",
    "\n",
    "image_sets['footwear'] = (cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/footwear_no/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/footwear_no/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/footwear_no/masks/footware_no_3_colour_mask_2_mask.png\", 0))\n",
    "\n",
    "image_sets['mugs'] = (cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/mugs_no/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/mugs_no/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/mugs_no/masks/3_colour_mask_2_mask.png\", 0))\n",
    "\n",
    "image_sets['tech'] = (cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/tech_no/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/tech_no/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 2 - Multiple Objects/tech_no/masks/tech_no_3_colour_mask_2_mask.png\", 0))"
   ]
  },
  {
   "source": [
    "Each image set uses two different inpainting techniques to remove an object, using its mask."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "statue 511.268857421875\n",
      "statue 454.6242350260417\n",
      "glasses 58.58229926215278\n",
      "glasses 58.63602973090278\n",
      "books 383.14044813368054\n",
      "books 327.18941514756943\n",
      "footwear 90.38670247395834\n",
      "footwear 68.19457790798612\n",
      "mugs 84.31249240451389\n",
      "mugs 75.38237413194445\n",
      "tech 144.83847005208332\n",
      "tech 118.37105577256945\n"
     ]
    }
   ],
   "source": [
    "for name, (s1, s2, mask) in image_sets.items():\n",
    "    paint_ns = cv2.inpaint(s2, mask, 20, cv2.INPAINT_NS)\n",
    "    paint_telea = cv2.inpaint(s2, mask, 20, cv2.INPAINT_TELEA)\n",
    "    print(name, \"images:\")\n",
    "    print(\"NS\", CompareResult(s1, paint_ns, 2))\n",
    "    print(\"Telea\", CompareResult(s1, paint_telea, 2))"
   ]
  },
  {
   "source": [
    "# Task B"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complex_sets = {} # 'set name': (s1, s2, mask)\n",
    "complex_sets['food'] = (cv2.imread(\"COTSDataset/Part 3 - Complex Background/foodA_nw_no/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/foodA_nw_no/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/foodA_nw_no/\", 0))\n",
    "\n",
    "complex_sets['statues'] = (cv2.imread(\"COTSDataset/Part 3 - Complex Background/statuesB_w_no/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/statuesB_w_no/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/statuesB_w_no/\", 0))\n",
    "\n",
    "complex_sets['souvenirs'] = (cv2.imread(\"COTSDataset/Part 3 - Complex Background/souvenirsB_nw_no/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/souvenirsB_nw_no/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/souvenirsB_nw_no/\", 0))\n",
    "\n",
    "complex_sets['books'] = (cv2.imread(\"COTSDataset/Part 3 - Complex Background/booksC_w_no/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/booksC_w_no/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/booksC_w_no/\", 0))\n",
    "\n",
    "complex_sets['cups'] = (cv2.imread(\"COTSDataset/Part 3 - Complex Background/cupsA_w_oc/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/cupsA_w_oc/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/cupsA_w_oc/\", 0))\n",
    "\n",
    "complex_sets['electronics'] = (cv2.imread(\"COTSDataset/Part 3 - Complex Background/electronicsA_nw_no/1_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/electronicsA_nw_no/2_colour.jpeg\"), cv2.imread(\"COTSDataset/Part 3 - Complex Background/electronicsA_nw_no/\", 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "com1 = cv2.imread(\"COTSDataset/Part 3 - Complex Background/cupsA_nw_no/3_colour.jpeg\", 1)\n",
    "commask1 = cv2.imread(\"COTSDataset/Part 3 - Complex Background/masks/cupsa_nw_no/1_colour.png\", 0)\n",
    "cv2.imshow(\"Inpainted image\", com1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "inp1 = cv2.inpaint(com1, commask1, 150, cv2.INPAINT_TELEA)\n",
    "cv2.imshow(\"Inpainted image\", inp1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, (s1, s2, mask) in complex_sets.items():\r\n",
    "    paint_ns = cv2.inpaint(s2, mask, 20, cv2.INPAINT_NS)\r\n",
    "    paint_telea = cv2.inpaint(s2, mask, 20, cv2.INPAINT_TELEA)\r\n",
    "    print(name, \"images:\")\r\n",
    "    print(\"NS\", CompareResult(s1, paint_ns, 2))\r\n",
    "    print(\"Telea\", CompareResult(s1, paint_telea, 2))"
   ]
  }
 ]
}