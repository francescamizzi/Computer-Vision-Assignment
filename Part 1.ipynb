{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "source": [
    "# Stage 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = cv2.imread(\"Images/2_colour.jpeg\") #Scene with 2 objects\n",
    "mask = cv2.imread(\"Images/masks/souvenirs_no_3_colour_mask_2_mask.png\") #Target object mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractObject(S2, ObjectMask):\n",
    "    \"\"\"Extracts an object from an image scene based on the mask used\"\"\"\n",
    "\n",
    "    final_im = ObjectMask*S2\n",
    "    final_im = cv2.bitwise_not(final_im)\n",
    "    return final_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplyFilter(ExtractedObject, FilterIndex):\n",
    "    \"\"\"Applies convolution on the object using pre-defined image kernels\"\"\"\n",
    "\n",
    "    if FilterIndex==0: #Apply no filter\n",
    "        FilteredExObject = ExtractedObject\n",
    "    elif FilterIndex==1:\n",
    "        print(\"\")\n",
    "        #Will need to define some kernels and use them here\n",
    "    elif FilterIndex==2:\n",
    "        print(\"\")\n",
    "        #Will need to define some kernels and use them here\n",
    "    elif FilterIndex==2:\n",
    "        print(\"\")\n",
    "        #Will need to define some kernels and use them here\n",
    "    return FilteredExObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObjectBlender(S1, FilteredExObject):\n",
    "    \"\"\"Adds the filtered extracted object to the image in scene S1\"\"\"\n",
    "\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    BlendingResult = cv2.addWeighted(S1, alpha, FilteredExObject, beta, 0.0)\n",
    "    cv2.imshow('Blended', BlendingResult)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return BlendingResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareResult(BlendingResult, S2, metric):\n",
    "    \"\"\"Compares the blended image with the scene with 2 objects\"\"\"\n",
    "\n",
    "    if metric==1: #Sum of Squared Distance Error (SSD)\n",
    "        error = BlendingResult-S2\n",
    "        #error = sum(error(:).^2)\n",
    "    elif metric==2: #Mean Squared Error (MSE)\n",
    "        error = np.sum((BlendingResult.astype(\"float\") - S2.astype(\"float\")) ** 2)\n",
    "        error /= float(BlendingResult.shape[0] * BlendingResult.shape[1])\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = ExtractObject(s2, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = cv2.imread(\"Images/1_colour.jpeg\", 1) #Scene with 1 object\n",
    "blended = ObjectBlender(s1, extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20031.10287109375"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "CompareResult(blended, s2, 2)"
   ]
  },
  {
   "source": [
    "# Stage 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveGreen(img):\n",
    "    \"\"\"Removes the green background from an image\"\"\"\n",
    "\n",
    "    imgcop = np.copy(img)\n",
    "    imgcop = cv2.cvtColor(imgcop, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    lower_bound = np.array([31, 74, 40]) #Lower bound of green colour - darkest green\n",
    "    upper_bound = np.array([136, 199, 179])\n",
    "\n",
    "    greenscreen_mask = cv2.inRange(imgcop, lower_bound, upper_bound)\n",
    "    \n",
    "    masked_image = np.copy(imgcop)\n",
    "    masked_image[greenscreen_mask != 0] = [0, 0, 0]\n",
    "\n",
    "    cv2.imshow(\"Suppost elephant biss\", masked_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NewBackground(imgNoBg, NewBackground):\n",
    "    \"\"\"Replaces the background of an image with `NewBackground`\"\"\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_green = RemoveGreen(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/fnplus/blue-or-green-screen-effect-with-open-cv-chroma-keying-94d4a6ab2743\n",
    "new_back = cv2.imread(\"empty_controlled_depth8.png\")\n",
    "new_back = cv2.cvtColor(new_back, cv2.COLOR_BGR2RGB)\n",
    "new_image = NewBackground(no_green, new_back)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit (windows store)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "cd386f5f8c8f36ef4b4fcdd4abdd13db8063a0bb2969447e52ba0d537fcd437f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}