{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 1 of this task is concerned with blending an object, taken from one image, onto a scene in another image.\n",
    "\n",
    "Firstly, the two scenes and the object mask are loaded using *cv2* functions.\n",
    "\n",
    "**s1** is the scene containing a single object: an ornament elephant.\n",
    "\n",
    "**s2** is the scene containing two objects: an ornament elephant and a small ornament glass.\n",
    "\n",
    "**mask** is the object mask for the small ornament glass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = cv2.imread(\"Images/1_colour.jpeg\", 1) #Scene with 1 object\n",
    "s2 = cv2.imread(\"Images/2_colour.jpeg\") #Scene with 2 objects\n",
    "s3 = cv2.imread(\"Images/3_colour.jpeg\")\n",
    "green = cv2.imread(\"Images/green.jpeg\")\n",
    "mask = cv2.imread(\"Images/masks/souvenirs_no_3_colour_mask_2_mask.png\") #Target object mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractObject(S2, ObjectMask):\n",
    "    \"\"\"Extracts an object from an image scene based on the mask used\"\"\"\n",
    "\n",
    "    final_im = ObjectMask*S2\n",
    "    final_im = cv2.bitwise_not(final_im)\n",
    "    return final_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplyFilter(ExtractedObject, FilterIndex):\n",
    "    \"\"\"Applies convolution on the object using pre-defined image kernels\"\"\"\n",
    "\n",
    "    if FilterIndex==0: #Apply no filter\n",
    "        FilteredExObject = ExtractedObject\n",
    "    elif FilterIndex==1:\n",
    "        print(\"\")\n",
    "        #Will need to define some kernels and use them here\n",
    "    elif FilterIndex==2:\n",
    "        print(\"\")\n",
    "        #Will need to define some kernels and use them here\n",
    "    elif FilterIndex==2:\n",
    "        print(\"\")\n",
    "        #Will need to define some kernels and use them here\n",
    "    return FilteredExObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ObjectBlender(S1, FilteredExObject):\n",
    "    \"\"\"Adds the filtered extracted object to the image in scene S1\"\"\"\n",
    "\n",
    "    alpha = 0.5\n",
    "    beta = 1.0 - alpha\n",
    "    BlendingResult = cv2.addWeighted(S1, alpha, FilteredExObject, beta, 0.0)\n",
    "    cv2.imshow('Blended', BlendingResult)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return BlendingResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CompareResult(BlendingResult, S2, metric):\n",
    "    \"\"\"Compares the blended image with the scene with 2 objects\"\"\"\n",
    "\n",
    "    if metric==1: #Sum of Squared Distance Error (SSD)\n",
    "        error = BlendingResult-S2\n",
    "        #error = sum(error(:).^2)\n",
    "    elif metric==2: #Mean Squared Error (MSE)\n",
    "        error = np.sum((BlendingResult.astype(\"float\") - S2.astype(\"float\")) ** 2)\n",
    "        error /= float(BlendingResult.shape[0] * BlendingResult.shape[1])\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = ExtractObject(s2, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "blended = ObjectBlender(s1, extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20031.10287109375"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompareResult(blended, s2, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stage 2 of this task is concerned with removing the green background from an image and replacing it with another background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RemoveGreen(img):\n",
    "    \"\"\"Removes the green background from an image\"\"\"\n",
    "\n",
    "    lower_bound = np.array([47,75,31]) #Upper bound of green colour\n",
    "    upper_bound = np.array([85,112,48])\n",
    "    mask = cv2.inRange(img, lower_bound, upper_bound)\n",
    "#     test = cv2.bitwise_and(img, img, mask = mask)\n",
    "    test = cv2.bitwise_not(img)\n",
    "\n",
    "    cv2.imshow(\"Image without background\", test)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "RemoveGreen(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NewBackground(imgNoBg, NewBackground):\n",
    "    \"\"\"Replaces the background of an image with NewBackground\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedImage:\n",
    "    def __init__(self, mask, image):\n",
    "        self.mask = mask\n",
    "        self.image = image\n",
    "\n",
    "def process_foreground_image(self, frame, lower_green, upper_green):\n",
    "    \"\"\"Create an image mask to change green pixels to black on the foreground image\"\"\"\n",
    "    img = np.copy(frame)\n",
    "\n",
    "    mask = cv2.inRange(img, lower_green, upper_green)\n",
    "\n",
    "    masked_image = np.copy(img)\n",
    "    masked_image[mask != 0] = [0, 0, 0]\n",
    "\n",
    "    return MaskedImage(mask, masked_image)\n",
    "\n",
    "def process_background_image(self, background_frame, mask):\n",
    "    \"\"\"Create another image mask to turn non-green pixels black on the background image\"\"\"\n",
    "    background_image = cv2.cvtColor(background_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    crop_background = cv2.resize(background_image,\n",
    "                                 (self.signal_width,\n",
    "                                  self.signal_height))\n",
    "    crop_background[mask == 0] = [0, 0, 0]\n",
    "    return crop_background\n",
    "\n",
    "def chroma_key_image(self, frame, background_image, lower_green=None, upper_green=None):\n",
    "    \"\"\"Chroma key image method.\"\"\"\n",
    "    lower_green = lower_green if lower_green is not None else ([0, 100, 0])\n",
    "    upper_green = upper_green if upper_green is not None else ([80, 255, 40])\n",
    "\n",
    "    if frame is None or background_image is None:\n",
    "        raise RuntimeError(\"Foreground or background image is null.\")\n",
    "\n",
    "    cv2.normalize(frame, frame, 0, 255, cv2.NORM_MINMAX)\n",
    "    foreground = self.__process_foreground_image(frame, lower_green, upper_green)\n",
    "    background = self.__process_background_image(background_image, foreground.mask)\n",
    "\n",
    "    return np.array(foreground.image + background)\n",
    "\n",
    "def test(img,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "chroma_key_image() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-51e3f3530c9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchroma_key_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgreen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: chroma_key_image() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "chroma_key_image(frame = s3, background_image = green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9db377eb99f2f0001687ee5f0a8c7059c0f00fe46be8b7ead3eb64d7e1b83ff"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
